<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>AI Frame Analyzer — Transparent Video Vision</title>
  <!-- Tailwind CSS CDN (only external dependency) -->
  <script src="https://cdn.tailwindcss.com"></script>
  <!-- GENERATED_BY: PROMPT3.1 -->
  <style>
    /* Small, tasteful tweaks */
    .log-area { font-variant-numeric: tabular-nums; }
    .status-dot { width: .5rem; height: .5rem; }
    .thumb { image-rendering: -webkit-optimize-contrast; }
    .btn:disabled { opacity:.5; cursor:not-allowed; }
    .pill { @apply text-xs px-2 py-1 rounded-full border; }
  </style>
</head>
<body class="bg-slate-50 text-slate-900">
  <header class="border-b bg-white">
    <div class="max-w-6xl mx-auto px-4 py-4 flex items-center justify-between gap-4">
      <h1 class="text-xl sm:text-2xl font-semibold tracking-tight">AI Frame Analyzer</h1>
      <div class="flex items-center gap-2">
        <span id="statusDot" class="status-dot rounded-full bg-slate-300 inline-block"></span>
        <span id="statusText" class="text-sm font-medium text-slate-600">Ready</span>
      </div>
    </div>
  </header>

  <main class="max-w-6xl mx-auto px-4 py-6 grid grid-cols-1 lg:grid-cols-5 gap-6">
    <!-- Left column: Controls + Player + Logs -->
    <section class="lg:col-span-2 space-y-4">
      <!-- Controls Card -->
      <div class="bg-white border rounded-2xl shadow-sm p-4 space-y-4">
        <h2 class="text-lg font-semibold">1) Load a Video & Your Gemini API Key</h2>
        <div class="grid grid-cols-1 gap-3">
          <label class="block">
            <span class="text-sm font-medium">Select video file</span>
            <input id="fileInput" type="file" accept="video/*"
                   class="mt-1 block w-full rounded-lg border-slate-300 focus:border-indigo-500 focus:ring-indigo-500"/>
          </label>

          <div class="grid grid-cols-1 sm:grid-cols-2 gap-3">
            <label class="block">
              <span class="text-sm font-medium">Gemini API Key</span>
              <input id="apiKeyInput" type="password" placeholder="AIza..."
                     class="mt-1 block w-full rounded-lg border-slate-300 focus:border-indigo-500 focus:ring-indigo-500"/>
            </label>
            <label class="block">
              <span class="text-sm font-medium">Interval (seconds)</span>
              <input id="intervalInput" type="number" min="1" step="1" value="5"
                     class="mt-1 block w-full rounded-lg border-slate-300 focus:border-indigo-500 focus:ring-indigo-500"/>
            </label>
          </div>

          <!-- Restored: Model selector -->
          <label class="block">
            <span class="text-sm font-medium">Model (Gemini)</span>
            <select id="modelSelect"
                    class="mt-1 block w-full rounded-lg border-slate-300 focus:border-indigo-500 focus:ring-indigo-500">
              <option value="gemini-1.5-flash-latest" selected>gemini-1.5-flash-latest (fast, multi-modal)</option>
              <option value="gemini-1.5-pro-latest">gemini-1.5-pro-latest (higher quality)</option>
            </select>
          </label>

          <!-- NEW: Perspective selection -->
          <label class="block">
            <span class="text-sm font-medium">Analysis Perspective</span>
            <select id="perspectiveSelect"
                    class="mt-1 block w-full rounded-lg border-slate-300 focus:border-indigo-500 focus:ring-indigo-500">
              <option value="objective" selected>Objective Description</option>
              <option value="urban">Urban Planning Analysis</option>
              <option value="social">Social Dynamics Analysis</option>
              <option value="safety">Safety Assessment</option>
              <option value="accessibility">Accessibility Review</option>
              <option value="fiction">Creative Fiction (First-Person Story)</option>
            </select>
            <p class="text-xs text-slate-500 mt-1">You can change perspective anytime. Use “Re-analyze with New Perspective” to reuse captured frames.</p>
          </label>

          <div class="flex flex-col sm:flex-row items-stretch sm:items-center justify-between gap-3">
            <div class="flex gap-2">
              <button id="analyzeBtn"
                      class="btn inline-flex items-center justify-center rounded-xl bg-indigo-600 px-4 py-2.5 text-white font-medium hover:bg-indigo-700 transition disabled:hover:bg-indigo-600">
                Analyze Video
              </button>
              <button id="reanalyzeBtn"
                      class="btn inline-flex items-center justify-center rounded-xl bg-amber-600 px-4 py-2.5 text-white font-medium hover:bg-amber-700 transition disabled:hover:bg-amber-600" disabled>
                Re-analyze with New Perspective
              </button>
            </div>
            <div class="flex items-center gap-3">
              <span class="text-sm text-slate-600"><span id="progressText">0 / 0</span></span>
              <button id="downloadBtn"
                      class="btn inline-flex items-center justify-center rounded-xl bg-slate-800 px-3 py-2 text-white font-medium hover:bg-slate-900 transition disabled:opacity-50" disabled>
                Download Analysis
              </button>
            </div>
          </div>

          <p class="text-xs text-slate-500">
            Your API key is only used from your browser to call the official Google Generative Language API.
            Consider rotating keys regularly and be mindful of usage limits.
          </p>
        </div>
      </div>

      <!-- Player Card -->
      <div class="bg-white border rounded-2xl shadow-sm p-4 space-y-3">
        <h2 class="text-lg font-semibold">2) Preview Player</h2>
        <video id="video" controls class="w-full rounded-xl bg-slate-100 hidden"></video>
        <!-- Offscreen canvas used for exact frame capture (kept hidden) -->
        <canvas id="canvas" class="hidden"></canvas>
        <div class="text-sm text-slate-600">
          <p>During analysis, the video is paused and the player is programmatically <em>seeked</em> to 0s, 5s, 10s, … until the end.</p>
        </div>
      </div>

      <!-- Debug Logs -->
      <div class="bg-white border rounded-2xl shadow-sm p-4 space-y-2">
        <div class="flex items-center justify-between">
          <h2 class="text-lg font-semibold">3) Debug Log</h2>
          <button id="clearLogBtn" class="text-sm text-indigo-600 hover:underline">Clear</button>
        </div>
        <div id="log" class="log-area h-56 overflow-auto whitespace-pre-wrap text-xs bg-slate-50 border rounded-lg p-3"></div>
      </div>
    </section>

    <!-- Right column: Results -->
    <section class="lg:col-span-3 space-y-4">
      <div class="bg-white border rounded-2xl shadow-sm p-4">
        <div class="flex items-center justify-between mb-3 gap-3">
          <h2 class="text-lg font-semibold">4) Visual Transparency: Frame-by-Frame Results</h2>
          <div class="flex items-center gap-2">
            <span class="pill border-slate-300 text-slate-700" id="activePerspectivePill">Perspective: Objective Description</span>
          </div>
        </div>
        <div id="results" class="grid sm:grid-cols-2 gap-4 max-h-[70vh] overflow-auto pr-1">
          <!-- Cards with: timestamp, thumbnail, AI description -->
        </div>
        <p class="text-xs text-slate-500 mt-3">
          Each card shows the captured frame (exact Canvas snapshot at the timestamp) and the AI’s description.
          Compare them to verify accuracy.
        </p>
      </div>
    </section>
  </main>

  <footer class="max-w-6xl mx-auto px-4 pb-10 text-xs text-slate-500">
    <p>Built for transparency and learning. Uses the Canvas API for precise frame capture and Gemini for image understanding.</p>
  </footer>

  <script>
    /******************************************************
     * Utility: Logger
     ******************************************************/
    class Logger {
      constructor(el) { this.el = el; }
      time() {
        const d = new Date();
        const t = d.toLocaleTimeString();
        const ms = String(d.getMilliseconds()).padStart(3, "0");
        return `${t}.${ms}`;
      }
      log(msg) {
        const line = `[${this.time()}] ${msg}`;
        this.el.textContent += (this.el.textContent ? "\n" : "") + line;
        this.el.scrollTop = this.el.scrollHeight;
      }
      clear() { this.el.textContent = ""; }
    }

    /******************************************************
     * Perspective Manager
     * - Maps UI selection → prompt text and labels
     ******************************************************/
    class PerspectiveManager {
      constructor() {
        this.map = {
          objective: {
            label: "Objective Description",
            prompt: "Describe what you see in this video frame. Be objective and factual."
          },
          urban: {
            label: "Urban Planning Analysis",
            prompt: "Analyze this from an urban planning perspective: traffic flow, pedestrian infrastructure, accessibility features, public space design, and urban functionality."
          },
          social: {
            label: "Social Dynamics Analysis",
            prompt: "Analyze this from a sociological perspective: social interactions, group behavior, community dynamics, cultural patterns, and interpersonal relationships."
          },
          safety: {
            label: "Safety Assessment",
            prompt: "Analyze this from a safety perspective: identify potential hazards, risk factors, safety compliance issues, and protective measures."
          },
          accessibility: {
            label: "Accessibility Review",
            prompt: "Analyze this from an accessibility perspective: identify barriers, evaluate inclusive design features, assess mobility challenges, and note universal design elements."
          },
          fiction: {
            label: "Creative Fiction (First-Person Story)",
            prompt: "Pick one person visible in this frame and create a brief, respectful first-person narrative from their perspective. What might they be thinking or experiencing? Label clearly as creative fiction."
          }
        };
      }
      getPrompt(key) { return (this.map[key] || this.map.objective).prompt; }
      getLabel(key) { return (this.map[key] || this.map.objective).label; }
      isFiction(key) { return key === "fiction"; }
    }

    /******************************************************
     * API Manager
     * - Handles calls to the Google Generative Language API (Gemini).
     * - Sends both the analysis prompt and the frame image (PNG base64) as inline data.
     ******************************************************/
    class APIManager {
      constructor({ apiKeyProvider, modelProvider, logger }) {
        this.apiKeyProvider = apiKeyProvider; // function returning current API key
        this.modelProvider = modelProvider;   // function returning current model id
        this.logger = logger;
        this.endpointBase = "https://generativelanguage.googleapis.com/v1beta";
      }

      async analyzeFrame({ base64Image, promptText }) {
        const apiKey = this.apiKeyProvider();
        const model = this.modelProvider();
        if (!apiKey) throw new Error("Missing API key.");
        if (!model) throw new Error("Missing model id.");

        const url = `${this.endpointBase}/models/${encodeURIComponent(model)}:generateContent?key=${encodeURIComponent(apiKey)}`;

        // Remove "data:image/png;base64," prefix for inline_data.data
        const cleanBase64 = base64Image.replace(/^data:image\/png;base64,/, "");

        const body = {
          contents: [{
            parts: [
              { text: promptText },
              { inline_data: { mime_type: "image/png", data: cleanBase64 } }
            ]
          }],
          generationConfig: {
            temperature: 0.2,
            maxOutputTokens: 256
          }
        };

        this.logger.log(`API call → ${model} (image + prompt)`);

        const res = await fetch(url, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(body)
        });

        if (!res.ok) {
          const text = await res.text().catch(() => "");
          let reason = `${res.status} ${res.statusText}`;
          if (res.status === 429) reason += " (rate limit)";
          throw new Error(`API error: ${reason}. ${text || ""}`.trim());
        }

        const data = await res.json();
        // Extract the first candidate's text (robust parsing)
        const candidates = data.candidates || [];
        const first = candidates[0] || {};
        const content = first.content || {};
        const parts = content.parts || [];
        const textPart = parts.find(p => typeof p.text === "string");
        const output = textPart ? textPart.text : "(No description returned)";
        this.logger.log(`API response ✓`);
        return output;
      }
    }

    /******************************************************
     * Video Player
     * - Loads user-selected file and exposes metadata.
     * - Provides seek utilities for precise frame capture.
     ******************************************************/
    class VideoPlayer {
      constructor({ videoEl, logger, onReady }) {
        this.video = videoEl;
        this.logger = logger;
        this.onReady = onReady;
        this.ready = false;
        this.duration = 0;
        this.fileName = "";

        // Track basic player events
        this.video.addEventListener("play", () => this.logger.log("Event: play"));
        this.video.addEventListener("pause", () => this.logger.log("Event: pause"));
        this.video.addEventListener("seeking", () => this.logger.log(`Event: seeking → ${this.video.currentTime.toFixed(2)}s`));
        this.video.addEventListener("seeked", () => this.logger.log(`Event: seeked  → ${this.video.currentTime.toFixed(2)}s`));
        this.video.addEventListener("error", (e) => this.logger.log(`Video error: ${this.video.error?.message || e.message || "unknown"}`));
        this.video.addEventListener("loadedmetadata", () => {
          this.ready = true;
          this.duration = this.video.duration;
          this.logger.log(`Metadata loaded. Duration: ${this.duration.toFixed(2)}s, size: ${this.video.videoWidth}x${this.video.videoHeight}`);
          if (this.onReady) this.onReady();
        });
      }

      loadFile(file) {
        if (!file || !file.type.startsWith("video/")) throw new Error("Please select a valid video file.");
        const url = URL.createObjectURL(file);
        this.fileName = file.name || "video";
        this.logger.log(`Loading file: ${file.name} (${Math.round(file.size/1024)} KB)`);
        this.video.src = url;
        this.video.classList.remove("hidden");
        this.video.load();
      }

      pause() {
        if (!this.video.paused) {
          this.video.pause();
          this.logger.log("Paused video for analysis.");
        }
      }

      async seekTo(timeSec) {
        return new Promise((resolve, reject) => {
          const onSeeked = () => {
            cleanup();
            // Ensure the frame is actually ready to paint.
            if (this.video.readyState >= 2) {
              requestAnimationFrame(() => resolve());
            } else {
              setTimeout(() => resolve(), 50);
            }
          };
          const onError = () => { cleanup(); reject(new Error("Seek error.")); };
          const cleanup = () => {
            this.video.removeEventListener("seeked", onSeeked);
            this.video.removeEventListener("error", onError);
          };

          this.video.addEventListener("seeked", onSeeked, { once: true });
          this.video.addEventListener("error", onError, { once: true });
          this.video.currentTime = Math.min(timeSec, Math.max(0, this.duration - 0.01)); // avoid exact end
        });
      }
    }

    /******************************************************
     * Frame Analyzer
     * - Coordinates seeking, Canvas capture, and API calls.
     * - Sequentially processes frames: 0s, interval, 2*interval, …
     * - Caches frames for perspective re-analysis without re-capture.
     ******************************************************/
    class FrameAnalyzer {
      constructor({ videoPlayer, canvasEl, apiManager, resultsEl, logger, statusEl, statusDotEl, progressEl, perspectiveManager, perspectiveProvider, onCacheChange }) {
        this.vp = videoPlayer;
        this.canvas = canvasEl;
        this.ctx = this.canvas.getContext("2d", { willReadFrequently: true });
        this.api = apiManager;
        this.resultsEl = resultsEl;
        this.logger = logger;
        this.statusEl = statusEl;
        this.statusDotEl = statusDotEl;
        this.progressEl = progressEl;
        this.perspectives = perspectiveManager;
        this.getPerspectiveKey = perspectiveProvider;
        this.onCacheChange = onCacheChange;

        this.isAnalyzing = false;
        this.abort = false;

        /** Cached frames:
         * [{
         *   timestamp: number,
         *   dataUrl: string,
         *   descriptions: { [perspectiveKey]: string },
         *   cardEl: HTMLElement,
         *   descEl: HTMLElement
         * }]
         */
        this.frameCache = [];
      }

      setStatus(text, color) {
        this.statusEl.textContent = text;
        this.statusDotEl.className = `status-dot rounded-full ${color}`;
      }

      resetResults() {
        this.resultsEl.innerHTML = "";
        this.progressEl.textContent = "0 / 0";
        this.frameCache = [];
        if (this.onCacheChange) this.onCacheChange(this.frameCache.length);
      }

      _makeResultCard({ timestamp, dataUrl, description, perspectiveLabel }) {
        const card = document.createElement("div");
        card.className = "border rounded-xl p-3 bg-slate-50";
        card.innerHTML = `
          <div class="flex items-center justify-between mb-2">
            <span class="text-xs font-medium text-slate-700">t = ${timestamp.toFixed(2)}s</span>
            <span class="text-[10px] px-1.5 py-0.5 rounded-full border border-slate-300 text-slate-600">${perspectiveLabel}</span>
          </div>
          <img class="thumb w-full rounded-lg border bg-white" src="${dataUrl}" alt="Frame at ${timestamp.toFixed(2)}s"/>
          <div class="mt-2 text-sm whitespace-pre-wrap desc"></div>
        `;
        const descEl = card.querySelector(".desc");
        descEl.textContent = description;
        this.resultsEl.appendChild(card);
        return { card, descEl };
      }

      captureFrameAsPNG() {
        // Ensure canvas size matches actual video frame size for pixel-perfect capture.
        const vw = this.vp.video.videoWidth || 640;
        const vh = this.vp.video.videoHeight || 360;
        if (this.canvas.width !== vw || this.canvas.height !== vh) {
          this.canvas.width = vw;
          this.canvas.height = vh;
        }

        // Draw current video frame to canvas.
        this.ctx.drawImage(this.vp.video, 0, 0, vw, vh);

        // Export PNG data URL.
        const dataUrl = this.canvas.toDataURL("image/png");
        return dataUrl;
      }

      async analyzeAll({ intervalSec }) {
        if (!this.vp.ready) throw new Error("Video not ready.");
        if (this.isAnalyzing) throw new Error("Already analyzing.");

        // Determine current perspective
        const pKey = this.getPerspectiveKey();
        const prompt = this.perspectives.getPrompt(pKey);
        const pLabel = this.perspectives.getLabel(pKey);

        this.isAnalyzing = true;
        this.abort = false;
        this.vp.pause();
        this.setStatus("Analyzing…", "bg-amber-500");
        this.logger.log(`Starting analysis sequence. Perspective: ${pLabel}`);

        // Calculate timestamps: 0, interval, ..., <= duration
        const duration = this.vp.duration;
        const stamps = [];
        for (let t = 0; t <= duration; t += intervalSec) {
          stamps.push(+t.toFixed(2));
        }
        if (stamps[stamps.length - 1] < duration - 0.25) {
          stamps.push(+duration.toFixed(2)); // ensure we capture near the end
        }
        this.logger.log(`Planned frames: ${stamps.length} @ ${intervalSec}s interval.`);
        this.progressEl.textContent = `0 / ${stamps.length}`;

        this.resetResults(); // fresh run clears cache/cards
        let completed = 0;

        try {
          for (const t of stamps) {
            if (this.abort) { throw new Error("Aborted by user."); }
            this.logger.log(`Seeking → ${t.toFixed(2)}s`);
            await this.vp.seekTo(t);

            this.logger.log("Capturing frame via Canvas API…");
            const pngDataUrl = this.captureFrameAsPNG();

            this.logger.log("Calling AI for description…");
            const description = await this.api.analyzeFrame({
              base64Image: pngDataUrl,
              promptText: prompt
            });

            const { card, descEl } = this._makeResultCard({
              timestamp: t,
              dataUrl: pngDataUrl,
              description,
              perspectiveLabel: this.perspectives.getLabel(pKey)
            });

            // Cache
            this.frameCache.push({
              timestamp: t,
              dataUrl: pngDataUrl,
              descriptions: { [pKey]: description },
              cardEl: card,
              descEl
            });

            completed++;
            this.progressEl.textContent = `${completed} / ${stamps.length}`;
          }

          this.setStatus("Complete", "bg-emerald-500");
          this.logger.log("Analysis complete.");
          if (this.onCacheChange) this.onCacheChange(this.frameCache.length);
        } catch (err) {
          this.setStatus("Error", "bg-rose-500");
          this.logger.log(`Analysis error: ${err.message}`);
          throw err;
        } finally {
          this.isAnalyzing = false;
        }
      }

      /** Re-run AI on cached frames with a new perspective without re-capturing. */
      async reanalyzeWithPerspective() {
        if (this.isAnalyzing) throw new Error("Already analyzing.");
        if (!this.frameCache.length) throw new Error("No frames cached. Run an analysis first.");

        const pKey = this.getPerspectiveKey();
        const prompt = this.perspectives.getPrompt(pKey);
        const pLabel = this.perspectives.getLabel(pKey);

        this.isAnalyzing = true;
        this.setStatus("Re-analyzing…", "bg-amber-500");
        this.logger.log(`Re-analysis over ${this.frameCache.length} cached frames. Perspective: ${pLabel}`);
        this.progressEl.textContent = `0 / ${this.frameCache.length}`;

        let idx = 0;
        try {
          for (const item of this.frameCache) {
            const pngDataUrl = item.dataUrl;

            const description = await this.api.analyzeFrame({
              base64Image: pngDataUrl,
              promptText: prompt
            });

            item.descriptions[pKey] = description;

            // Update the card label and text in-place
            const labelEl = item.cardEl.querySelector("div > span:last-child");
            if (labelEl) labelEl.textContent = pLabel;
            item.descEl.textContent = description;

            idx++;
            this.progressEl.textContent = `${idx} / ${this.frameCache.length}`;
          }

          this.setStatus("Complete", "bg-emerald-500");
          this.logger.log("Re-analysis complete.");
        } catch (err) {
          this.setStatus("Error", "bg-rose-500");
          this.logger.log(`Re-analysis error: ${err.message}`);
          throw err;
        } finally {
          this.isAnalyzing = false;
        }
      }

      /** Export a professional text report of current perspective's analyses. */
      buildExportText({ fileName, perspectiveKey }) {
        const pLabel = this.perspectives.getLabel(perspectiveKey);
        const isFiction = this.perspectives.isFiction(perspectiveKey);
        const ts = new Date().toISOString();

        const lines = [];
        lines.push("AI Frame Analyzer — Report");
        lines.push("====================================");
        lines.push(`Video file        : ${fileName || "video"}`);
        lines.push(`Export timestamp  : ${ts}`);
        lines.push(`Perspective       : ${pLabel}`);
        lines.push(`Frames analyzed   : ${this.frameCache.length}`);
        lines.push("");
        lines.push("Frame-by-Frame Analysis");
        lines.push("------------------------------------");

        for (const item of this.frameCache) {
          const t = item.timestamp.toFixed(2);
          const text = item.descriptions[perspectiveKey] ?? "(No analysis for this perspective. Use Re-analyze.)";
          lines.push(`t = ${t}s`);
          if (isFiction) lines.push("[CREATIVE FICTION]");
          lines.push(text.trim());
          lines.push("");
        }

        return lines.join("\n");
      }
    }

    /******************************************************
     * App Wiring
     ******************************************************/
    (function init() {
      const els = {
        fileInput: document.getElementById("fileInput"),
        apiKeyInput: document.getElementById("apiKeyInput"),
        intervalInput: document.getElementById("intervalInput"),
        modelSelect: document.getElementById("modelSelect") || null, // robust
        perspectiveSelect: document.getElementById("perspectiveSelect"),
        analyzeBtn: document.getElementById("analyzeBtn"),
        reanalyzeBtn: document.getElementById("reanalyzeBtn"),
        downloadBtn: document.getElementById("downloadBtn"),
        clearLogBtn: document.getElementById("clearLogBtn"),
        video: document.getElementById("video"),
        canvas: document.getElementById("canvas"),
        results: document.getElementById("results"),
        log: document.getElementById("log"),
        statusText: document.getElementById("statusText"),
        statusDot: document.getElementById("statusDot"),
        progressText: document.getElementById("progressText"),
        activePerspectivePill: document.getElementById("activePerspectivePill"),
      };

      const logger = new Logger(els.log);
      const perspectives = new PerspectiveManager();

      const videoPlayer = new VideoPlayer({
        videoEl: els.video,
        logger,
        onReady: () => {
          setStatus("Ready", "bg-slate-300");
        }
      });

      function getApiKey() { return els.apiKeyInput.value.trim(); }
      function getModel() {
        const el = els.modelSelect;
        return (el && el.value) ? el.value.trim() : "gemini-1.5-flash-latest";
      }
      function getPerspectiveKey() { return els.perspectiveSelect.value; }
      function setPerspectivePill() {
        els.activePerspectivePill.textContent = "Perspective: " + perspectives.getLabel(getPerspectiveKey());
      }

      const apiManager = new APIManager({
        apiKeyProvider: getApiKey,
        modelProvider: getModel,
        logger
      });

      const analyzer = new FrameAnalyzer({
        videoPlayer,
        canvasEl: els.canvas,
        apiManager,
        resultsEl: els.results,
        logger,
        statusEl: els.statusText,
        statusDotEl: els.statusDot,
        progressEl: els.progressText,
        perspectiveManager: perspectives,
        perspectiveProvider: getPerspectiveKey,
        onCacheChange: (count) => {
          els.reanalyzeBtn.disabled = count === 0;
          els.downloadBtn.disabled = count === 0;
        }
      });

      function setStatus(text, dotColor) {
        els.statusText.textContent = text;
        els.statusDot.className = `status-dot rounded-full ${dotColor}`;
      }

      // UI: File selection
      els.fileInput.addEventListener("change", () => {
        const file = els.fileInput.files?.[0];
        try {
          analyzer.resetResults();
          if (file) {
            videoPlayer.loadFile(file);
            setStatus("Loading…", "bg-sky-500");
            logger.log(`User selected: ${file.name}`);
          }
        } catch (e) {
          setStatus("Error", "bg-rose-500");
          logger.log(`File load error: ${e.message}`);
          alert(e.message);
        }
      });

      // UI: Analyze
      els.analyzeBtn.addEventListener("click", async () => {
        if (!els.fileInput.files?.[0]) {
          alert("Please select a video file first.");
          return;
        }
        if (!getApiKey()) {
          alert("Please enter your Gemini API key.");
          return;
        }
        els.analyzeBtn.disabled = true;
        els.reanalyzeBtn.disabled = true;
        els.downloadBtn.disabled = true;
        try {
          const intervalSec = Math.max(1, Number(els.intervalInput.value || 5));
          await analyzer.analyzeAll({ intervalSec });
        } catch (e) {
          alert(`Analysis failed: ${e.message}`);
        } finally {
          els.analyzeBtn.disabled = false;
          els.reanalyzeBtn.disabled = analyzer.frameCache.length === 0;
          els.downloadBtn.disabled = analyzer.frameCache.length === 0;
        }
      });

      // UI: Re-analyze with new perspective (no re-capture)
      els.reanalyzeBtn.addEventListener("click", async () => {
        if (!getApiKey()) {
          alert("Please enter your Gemini API key.");
          return;
        }
        els.analyzeBtn.disabled = true;
        els.reanalyzeBtn.disabled = true;
        els.downloadBtn.disabled = true;
        try {
          await analyzer.reanalyzeWithPerspective();
        } catch (e) {
          alert(`Re-analysis failed: ${e.message}`);
        } finally {
          els.analyzeBtn.disabled = false;
          els.reanalyzeBtn.disabled = analyzer.frameCache.length === 0;
          els.downloadBtn.disabled = analyzer.frameCache.length === 0;
        }
      });

      // UI: Download analysis (text file)
      els.downloadBtn.addEventListener("click", () => {
        if (!analyzer.frameCache.length) {
          alert("Nothing to export. Run an analysis first.");
          return;
        }
        const pKey = getPerspectiveKey();
        const text = analyzer.buildExportText({
          fileName: videoPlayer.fileName,
          perspectiveKey: pKey
        });
        const blob = new Blob([text], { type: "text/plain;charset=utf-8" });
        const url = URL.createObjectURL(blob);
        const a = document.createElement("a");
        const base = (videoPlayer.fileName || "video").replace(/\.[^/.]+$/, "");
        const stamp = new Date().toISOString().replace(/[:.]/g, "-");
        const pSlug = perspectives.getLabel(pKey).replace(/\s+/g, "_");
        a.href = url;
        a.download = `${base}__analysis_${pSlug}__${stamp}.txt`;
        document.body.appendChild(a);
        a.click();
        document.body.removeChild(a);
        URL.revokeObjectURL(url);
        logger.log("Exported analysis as .txt");
      });

      // UI: Clear log
      els.clearLogBtn.addEventListener("click", () => {
        logger.clear();
      });

      // UI: Perspective pill updates on change
      els.perspectiveSelect.addEventListener("change", setPerspectivePill);
      setPerspectivePill();

      // Initial status
      setStatus("Ready", "bg-slate-300");
      logger.log("App ready.");
      logger.log("Tip: Load a small-ish MP4 for quickest results. Large/long videos mean many API calls.");
    })();
  </script>

  <!--
    IMPLEMENTATION NOTES (for learning):
    - Canvas API & Timing:
      We wait for the video to emit "seeked", then let requestAnimationFrame run before drawImage().
      This ensures the exact frame at that timestamp is ready to be painted into the Canvas.
      The Canvas dimensions are set to the video's intrinsic width/height for pixel-accurate capture.
      The PNG is read via canvas.toDataURL("image/png") and passed to the API as inline base64.
    - Sequential Processing & Async:
      analyzeAll() iterates timestamps sequentially with await. We only proceed to the next frame
      after the current seek → capture → API call completes. This provides transparent order and
      simplifies rate limiting.
    - Perspective System:
      The PerspectiveManager centralizes labels and prompts. The current selection is applied both to
      initial analysis and re-analysis. Re-analysis reuses cached PNGs without seeking or re-capturing.
      Creative fiction frames are clearly labeled in the export.
    - Export:
      "Download Analysis" produces a professional, plain-text report with filename, timestamp,
      perspective, total frames, and frame-by-frame results. For creative fiction, each section is
      explicitly marked.
    - Error Handling:
      All critical steps are try/catch wrapped. Video seek errors, API non-200 responses, and
      network/rate limit issues result in a visible status "Error" and a logged message.
    - Security:
      This demo uses the API key directly from the browser for simplicity and transparency.
      For production, proxy calls through a secure backend and keep keys server-side.
  -->
</body>
</html>
