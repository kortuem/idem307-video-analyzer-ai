<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>AI Frame Analyzer — Transparent Video Vision</title>
  <!-- Tailwind CSS CDN (only external dependency) -->
  <script src="https://cdn.tailwindcss.com"></script>
  <!-- GENERATED_BY: PROMPT2.1 -->
  <style>
    /* Small, tasteful tweaks */
    .log-area { font-variant-numeric: tabular-nums; }
    .status-dot { width: .5rem; height: .5rem; }
    .thumb { image-rendering: -webkit-optimize-contrast; }
    .btn:disabled { opacity:.5; cursor:not-allowed; }
  </style>
</head>
<body class="bg-slate-50 text-slate-900">
  <header class="border-b bg-white">
    <div class="max-w-6xl mx-auto px-4 py-4 flex items-center justify-between gap-4">
      <h1 class="text-xl sm:text-2xl font-semibold tracking-tight">AI Frame Analyzer</h1>
      <div class="flex items-center gap-2">
        <span id="statusDot" class="status-dot rounded-full bg-slate-300 inline-block"></span>
        <span id="statusText" class="text-sm font-medium text-slate-600">Ready</span>
      </div>
    </div>
  </header>

  <main class="max-w-6xl mx-auto px-4 py-6 grid grid-cols-1 lg:grid-cols-5 gap-6">
    <!-- Left column: Controls + Player + Logs -->
    <section class="lg:col-span-2 space-y-4">
      <!-- Controls Card -->
      <div class="bg-white border rounded-2xl shadow-sm p-4 space-y-4">
        <h2 class="text-lg font-semibold">1) Load a Video & Your Gemini API Key</h2>
        <div class="grid grid-cols-1 gap-3">
          <label class="block">
            <span class="text-sm font-medium">Select video file</span>
            <input id="fileInput" type="file" accept="video/*"
                   class="mt-1 block w-full rounded-lg border-slate-300 focus:border-indigo-500 focus:ring-indigo-500"/>
          </label>
          <div class="grid grid-cols-1 sm:grid-cols-2 gap-3">
            <label class="block">
              <span class="text-sm font-medium">Gemini API Key</span>
              <input id="apiKeyInput" type="password" placeholder="AIza..."
                     class="mt-1 block w-full rounded-lg border-slate-300 focus:border-indigo-500 focus:ring-indigo-500"/>
            </label>
            <label class="block">
              <span class="text-sm font-medium">Interval (seconds)</span>
              <input id="intervalInput" type="number" min="1" step="1" value="5"
                     class="mt-1 block w-full rounded-lg border-slate-300 focus:border-indigo-500 focus:ring-indigo-500"/>
            </label>
          </div>
          <label class="block">
            <span class="text-sm font-medium">Model (Gemini)</span>
            <select id="modelSelect"
                    class="mt-1 block w-full rounded-lg border-slate-300 focus:border-indigo-500 focus:ring-indigo-500">
              <option value="gemini-1.5-flash-latest" selected>gemini-1.5-flash-latest (fast, multi-modal)</option>
              <option value="gemini-1.5-pro-latest">gemini-1.5-pro-latest (higher quality)</option>
            </select>
          </label>
          <div class="flex items-center justify-between gap-3">
            <button id="analyzeBtn"
                    class="btn inline-flex items-center justify-center rounded-xl bg-indigo-600 px-4 py-2.5 text-white font-medium hover:bg-indigo-700 transition disabled:hover:bg-indigo-600">
              Analyze Video
            </button>
            <div class="text-sm text-slate-600">
              <span id="progressText">0 / 0</span>
            </div>
          </div>
          <p class="text-xs text-slate-500">
            Your API key is only used from your browser to call the official Google Generative Language API.
            Consider rotating keys regularly and be mindful of usage limits.
          </p>
        </div>
      </div>

      <!-- Player Card -->
      <div class="bg-white border rounded-2xl shadow-sm p-4 space-y-3">
        <h2 class="text-lg font-semibold">2) Preview Player</h2>
        <video id="video" controls class="w-full rounded-xl bg-slate-100 hidden"></video>
        <!-- Offscreen canvas used for exact frame capture (kept hidden) -->
        <canvas id="canvas" class="hidden"></canvas>
        <div class="text-sm text-slate-600">
          <p>During analysis, the video is paused and the player is programmatically <em>seeked</em> to 0s, 5s, 10s, … until the end.</p>
        </div>
      </div>

      <!-- Debug Logs -->
      <div class="bg-white border rounded-2xl shadow-sm p-4 space-y-2">
        <div class="flex items-center justify-between">
          <h2 class="text-lg font-semibold">3) Debug Log</h2>
          <button id="clearLogBtn" class="text-sm text-indigo-600 hover:underline">Clear</button>
        </div>
        <div id="log" class="log-area h-56 overflow-auto whitespace-pre-wrap text-xs bg-slate-50 border rounded-lg p-3"></div>
      </div>
    </section>

    <!-- Right column: Results -->
    <section class="lg:col-span-3 space-y-4">
      <div class="bg-white border rounded-2xl shadow-sm p-4">
        <h2 class="text-lg font-semibold mb-3">4) Visual Transparency: Frame-by-Frame Results</h2>
        <div id="results" class="grid sm:grid-cols-2 gap-4 max-h-[70vh] overflow-auto pr-1">
          <!-- Cards with: timestamp, thumbnail, AI description -->
        </div>
        <p class="text-xs text-slate-500 mt-3">
          Each card shows the captured frame (exact Canvas snapshot at the timestamp) and the AI’s description.
          Compare them to verify accuracy.
        </p>
      </div>
    </section>
  </main>

  <footer class="max-w-6xl mx-auto px-4 pb-10 text-xs text-slate-500">
    <p>Built for transparency and learning. Uses the Canvas API for precise frame capture and Gemini for image understanding.</p>
  </footer>

  <script>
    /******************************************************
     * Utility: Logger
     ******************************************************/
    class Logger {
      constructor(el) { this.el = el; }
      time() {
        const d = new Date();
        const t = d.toLocaleTimeString();
        const ms = String(d.getMilliseconds()).padStart(3, "0");
        return `${t}.${ms}`;
      }
      log(msg) {
        const line = `[${this.time()}] ${msg}`;
        this.el.textContent += (this.el.textContent ? "\n" : "") + line;
        this.el.scrollTop = this.el.scrollHeight;
      }
      clear() { this.el.textContent = ""; }
    }

    /******************************************************
     * API Manager
     * - Handles calls to the Google Generative Language API (Gemini).
     * - Sends both the analysis prompt and the frame image (PNG base64) as inline data.
     ******************************************************/
    class APIManager {
      constructor({ apiKeyProvider, modelProvider, logger }) {
        this.apiKeyProvider = apiKeyProvider; // function returning current API key
        this.modelProvider = modelProvider;   // function returning current model id
        this.logger = logger;
        this.endpointBase = "https://generativelanguage.googleapis.com/v1beta";
        this.defaultPrompt = "Describe what you see in this video frame. Be objective and factual.";
      }

      async analyzeFrame({ base64Image, promptText }) {
        const apiKey = this.apiKeyProvider();
        const model = this.modelProvider();
        if (!apiKey) throw new Error("Missing API key.");
        if (!model) throw new Error("Missing model id.");

        const url = `${this.endpointBase}/models/${encodeURIComponent(model)}:generateContent?key=${encodeURIComponent(apiKey)}`;

        // Remove "data:image/png;base64," prefix for inline_data.data
        const cleanBase64 = base64Image.replace(/^data:image\/png;base64,/, "");

        const body = {
          contents: [{
            parts: [
              { text: promptText || this.defaultPrompt },
              { inline_data: { mime_type: "image/png", data: cleanBase64 } }
            ]
          }],
          generationConfig: {
            temperature: 0.2,
            maxOutputTokens: 256
          }
        };

        this.logger.log(`API call → ${model} (image + prompt)`);

        const res = await fetch(url, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify(body)
        });

        if (!res.ok) {
          const text = await res.text().catch(() => "");
          let reason = `${res.status} ${res.statusText}`;
          if (res.status === 429) reason += " (rate limit)";
          throw new Error(`API error: ${reason}. ${text || ""}`.trim());
        }

        const data = await res.json();
        // Extract the first candidate's text (robust parsing)
        const candidates = data.candidates || [];
        const first = candidates[0] || {};
        const content = first.content || {};
        const parts = content.parts || [];
        const textPart = parts.find(p => typeof p.text === "string");
        const output = textPart ? textPart.text : "(No description returned)";
        this.logger.log(`API response ✓`);
        return output;
      }
    }

    /******************************************************
     * Video Player
     * - Loads user-selected file and exposes metadata.
     * - Provides seek utilities for precise frame capture.
     ******************************************************/
    class VideoPlayer {
      constructor({ videoEl, logger, onReady }) {
        this.video = videoEl;
        this.logger = logger;
        this.onReady = onReady;
        this.ready = false;
        this.duration = 0;

        // Track basic player events
        this.video.addEventListener("play", () => this.logger.log("Event: play"));
        this.video.addEventListener("pause", () => this.logger.log("Event: pause"));
        this.video.addEventListener("seeking", () => this.logger.log(`Event: seeking → ${this.video.currentTime.toFixed(2)}s`));
        this.video.addEventListener("seeked", () => this.logger.log(`Event: seeked  → ${this.video.currentTime.toFixed(2)}s`));
        this.video.addEventListener("error", (e) => this.logger.log(`Video error: ${this.video.error?.message || e.message || "unknown"}`));
        this.video.addEventListener("loadedmetadata", () => {
          this.ready = true;
          this.duration = this.video.duration;
          this.logger.log(`Metadata loaded. Duration: ${this.duration.toFixed(2)}s, size: ${this.video.videoWidth}x${this.video.videoHeight}`);
          if (this.onReady) this.onReady();
        });
      }

      loadFile(file) {
        if (!file || !file.type.startsWith("video/")) throw new Error("Please select a valid video file.");
        const url = URL.createObjectURL(file);
        this.logger.log(`Loading file: ${file.name} (${Math.round(file.size/1024)} KB)`);
        this.video.src = url;
        this.video.classList.remove("hidden");
        this.video.load();
      }

      pause() {
        if (!this.video.paused) {
          this.video.pause();
          this.logger.log("Paused video for analysis.");
        }
      }

      async seekTo(timeSec) {
        return new Promise((resolve, reject) => {
          const onSeeked = () => {
            cleanup();
            // Ensure the frame is actually ready to paint.
            if (this.video.readyState >= 2) {
              // Minor delay helps some browsers finish presenting the frame.
              requestAnimationFrame(() => resolve());
            } else {
              // Wait a bit and try again if needed.
              setTimeout(() => resolve(), 50);
            }
          };
          const onError = () => { cleanup(); reject(new Error("Seek error.")); };
          const cleanup = () => {
            this.video.removeEventListener("seeked", onSeeked);
            this.video.removeEventListener("error", onError);
          };

          this.video.addEventListener("seeked", onSeeked, { once: true });
          this.video.addEventListener("error", onError, { once: true });
          this.video.currentTime = Math.min(timeSec, Math.max(0, this.duration - 0.01)); // avoid exact end
        });
      }
    }

    /******************************************************
     * Frame Analyzer
     * - Coordinates seeking, Canvas capture, and API calls.
     * - Sequentially processes frames: 0s, interval, 2*interval, …
     ******************************************************/
    class FrameAnalyzer {
      constructor({ videoPlayer, canvasEl, apiManager, resultsEl, logger, statusEl, statusDotEl, progressEl }) {
        this.vp = videoPlayer;
        this.canvas = canvasEl;
        this.ctx = this.canvas.getContext("2d", { willReadFrequently: true });
        this.api = apiManager;
        this.resultsEl = resultsEl;
        this.logger = logger;
        this.statusEl = statusEl;
        this.statusDotEl = statusDotEl;
        this.progressEl = progressEl;

        this.isAnalyzing = false;
        this.abort = false;
      }

      setStatus(text, color) {
        this.statusEl.textContent = text;
        this.statusDotEl.className = `status-dot rounded-full ${color}`;
      }

      resetResults() {
        this.resultsEl.innerHTML = "";
        this.progressEl.textContent = "0 / 0";
      }

      appendResultCard({ timestamp, dataUrl, description }) {
        const card = document.createElement("div");
        card.className = "border rounded-xl p-3 bg-slate-50";
        card.innerHTML = `
          <div class="flex items-center justify-between mb-2">
            <span class="text-xs font-medium text-slate-700">t = ${timestamp.toFixed(2)}s</span>
          </div>
          <img class="thumb w-full rounded-lg border bg-white" src="${dataUrl}" alt="Frame at ${timestamp.toFixed(2)}s"/>
          <div class="mt-2 text-sm whitespace-pre-wrap">${description}</div>
        `;
        this.resultsEl.appendChild(card);
      }

      captureFrameAsPNG() {
        // Ensure canvas size matches actual video frame size for pixel-perfect capture.
        const vw = this.vp.video.videoWidth || 640;
        const vh = this.vp.video.videoHeight || 360;
        if (this.canvas.width !== vw || this.canvas.height !== vh) {
          this.canvas.width = vw;
          this.canvas.height = vh;
        }

        // Draw current video frame to canvas.
        // NOTE: Because we wait for "seeked" and a rAF, this grabs the *exact* frame at current time.
        this.ctx.drawImage(this.vp.video, 0, 0, vw, vh);

        // Export PNG data URL. We'll strip the base64 prefix before sending to the API.
        const dataUrl = this.canvas.toDataURL("image/png");
        return dataUrl;
      }

      async analyzeAll({ intervalSec }) {
        if (!this.vp.ready) throw new Error("Video not ready.");
        if (this.isAnalyzing) throw new Error("Already analyzing.");

        this.isAnalyzing = true;
        this.abort = false;
        this.vp.pause();
        this.setStatus("Analyzing…", "bg-amber-500");
        this.logger.log("Starting analysis sequence.");

        // Calculate timestamps: 0, interval, ..., <= duration
        const duration = this.vp.duration;
        const stamps = [];
        for (let t = 0; t <= duration; t += intervalSec) {
          stamps.push(+t.toFixed(2));
        }
        if (stamps[stamps.length - 1] < duration - 0.25) {
          stamps.push(+duration.toFixed(2)); // ensure we capture near the end
        }
        this.logger.log(`Planned frames: ${stamps.length} @ ${intervalSec}s interval.`);
        this.progressEl.textContent = `0 / ${stamps.length}`;

        let completed = 0;
        try {
          for (const t of stamps) {
            if (this.abort) { throw new Error("Aborted by user."); }
            this.logger.log(`Seeking → ${t.toFixed(2)}s`);
            await this.vp.seekTo(t);

            this.logger.log("Capturing frame via Canvas API…");
            const pngDataUrl = this.captureFrameAsPNG();

            this.logger.log("Calling AI for description…");
            const description = await this.api.analyzeFrame({
              base64Image: pngDataUrl,
              promptText: this.api.defaultPrompt
            });

            this.appendResultCard({ timestamp: t, dataUrl: pngDataUrl, description });
            completed++;
            this.progressEl.textContent = `${completed} / ${stamps.length}`;
          }

          this.setStatus("Complete", "bg-emerald-500");
          this.logger.log("Analysis complete.");
        } catch (err) {
          this.setStatus("Error", "bg-rose-500");
          this.logger.log(`Analysis error: ${err.message}`);
          throw err;
        } finally {
          this.isAnalyzing = false;
        }
      }
    }

    /******************************************************
     * App Wiring
     ******************************************************/
    (function init() {
      const els = {
        fileInput: document.getElementById("fileInput"),
        apiKeyInput: document.getElementById("apiKeyInput"),
        intervalInput: document.getElementById("intervalInput"),
        modelSelect: document.getElementById("modelSelect"),
        analyzeBtn: document.getElementById("analyzeBtn"),
        clearLogBtn: document.getElementById("clearLogBtn"),
        video: document.getElementById("video"),
        canvas: document.getElementById("canvas"),
        results: document.getElementById("results"),
        log: document.getElementById("log"),
        statusText: document.getElementById("statusText"),
        statusDot: document.getElementById("statusDot"),
        progressText: document.getElementById("progressText"),
      };

      const logger = new Logger(els.log);
      const videoPlayer = new VideoPlayer({
        videoEl: els.video,
        logger,
        onReady: () => {
          setStatus("Ready", "bg-slate-300");
        }
      });

      function getApiKey() { return els.apiKeyInput.value.trim(); }
      function getModel() { return els.modelSelect.value.trim(); }

      const apiManager = new APIManager({
        apiKeyProvider: getApiKey,
        modelProvider: getModel,
        logger
      });

      const analyzer = new FrameAnalyzer({
        videoPlayer,
        canvasEl: els.canvas,
        apiManager,
        resultsEl: els.results,
        logger,
        statusEl: els.statusText,
        statusDotEl: els.statusDot,
        progressEl: els.progressText
      });

      function setStatus(text, dotColor) {
        els.statusText.textContent = text;
        els.statusDot.className = `status-dot rounded-full ${dotColor}`;
      }

      // UI: File selection
      els.fileInput.addEventListener("change", () => {
        const file = els.fileInput.files?.[0];
        try {
          analyzer.resetResults();
          if (file) {
            videoPlayer.loadFile(file);
            setStatus("Loading…", "bg-sky-500");
            logger.log(`User selected: ${file.name}`);
          }
        } catch (e) {
          setStatus("Error", "bg-rose-500");
          logger.log(`File load error: ${e.message}`);
          alert(e.message);
        }
      });

      // UI: Analyze
      els.analyzeBtn.addEventListener("click", async () => {
        if (!els.fileInput.files?.[0]) {
          alert("Please select a video file first.");
          return;
        }
        if (!getApiKey()) {
          alert("Please enter your Gemini API key.");
          return;
        }
        // Defensive: disable button during run
        els.analyzeBtn.disabled = true;
        try {
          const intervalSec = Math.max(1, Number(els.intervalInput.value || 5));
          await analyzer.analyzeAll({ intervalSec });
        } catch (e) {
          // Already logged inside analyzer; surface a friendly message.
          alert(`Analysis failed: ${e.message}`);
        } finally {
          els.analyzeBtn.disabled = false;
        }
      });

      // UI: Clear log
      els.clearLogBtn.addEventListener("click", () => {
        logger.clear();
      });

      // Initial status
      setStatus("Ready", "bg-slate-300");
      logger.log("App ready.");
      logger.log("Tip: Load a small-ish MP4 for quickest results. Large/long videos mean many API calls.");
    })();
  </script>

  <!--
    IMPLEMENTATION NOTES (for learning):
    - Canvas API & Timing:
      We wait for the video to emit "seeked", then let requestAnimationFrame run before drawImage().
      This ensures the exact frame at that timestamp is ready to be painted into the Canvas.
      The Canvas dimensions are set to the video's intrinsic width/height for pixel-accurate capture.
      The PNG is read via canvas.toDataURL("image/png") and passed to the API as inline base64.
    - Sequential Processing & Async:
      analyzeAll() iterates timestamps sequentially with await. We only proceed to the next frame
      after the current seek → capture → API call completes. This provides transparent order and
      simplifies rate limiting.
    - Error Handling:
      All critical steps are try/catch wrapped. Video seek errors, API non-200 responses, and
      network/rate limit issues result in a visible status "Error" and a logged message.
    - Rate Limits:
      If you hit 429 Too Many Requests, reduce frame frequency (increase interval seconds), or
      switch to the flash model. Consider adding a delay or exponential backoff if needed.
    - Security:
      This demo uses the API key directly from the browser for simplicity and transparency.
      For production, proxy calls through a secure backend and keep keys server-side.
  -->
</body>
</html>
